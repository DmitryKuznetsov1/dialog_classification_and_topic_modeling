{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2255bc30-5da2-45e9-b927-12eb0dadfc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import pymorphy2\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f7de3b-98b8-48e5-84a5-02c2237e5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/topic_modeling_task_sample_trainPart.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8cb864-918a-4340-a577-ecc4e178bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['replicas'] = df['text_employer'].str.split('.')\n",
    "data = df[['ucid','replicas']].explode('replicas').reset_index(drop=True).dropna()\n",
    "data = data[data['replicas'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b164b331-306a-4dd5-b151-18308124aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "extra_stop_words = get_stopwords_from_file('stopwords.txt')\n",
    "stop_words_extended = set(stop_words + extra_stop_words)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def process_string(input_string, morph=morph, stop_words=stop_words_extended):\n",
    "    words = re.findall(r'\\b[а-яА-Я_]+\\b', input_string)\n",
    "    result_string = ' '.join([word if '_' in word else morph.parse(word)[0].normal_form for word in words if word not in stop_words])\n",
    "    \n",
    "    return result_string\n",
    "\n",
    "data['replicas'] = data['replicas'].apply(process_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c81c25-b9b4-419b-a9da-437c21245809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               добрый_день\n",
       "1         клиентский_менеджер виктория сбер бизнес звони...\n",
       "2                                                     знать\n",
       "3         понять ваш предложение который хотеть обсудить...\n",
       "4         возможность подключить бизнес кэшбэк зарабатыв...\n",
       "                                ...                        \n",
       "556210                                       ориентировочно\n",
       "556211                                               удобно\n",
       "556212                    какой вопрос другой продукт_банка\n",
       "556213    понять перезвонить следующий среда ориентирово...\n",
       "556214                                      добрый свидание\n",
       "Name: replicas, Length: 556215, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['replicas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0db4d89c-a62b-4c9e-a895-e326fae0f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data.replicas, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf62497-8fd7-4119-b154-986a2e6e7873",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d100ec76-294e-4ea0-b09c-2ec9e27fe6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111243, 10712)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_ben = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=stopwords.words('russian'),\n",
    "    # max_features=10000,\n",
    ")\n",
    "train_vec_ben = vector_ben.fit_transform(X_train)\n",
    "test_vec_ben = vector_ben.transform(X_test)\n",
    "train_vec_ben.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2012df7-e06b-449a-bf73-ba7e8888ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    }
   ],
   "source": [
    "lda_model_ben = LatentDirichletAllocation(\n",
    "        n_components=15,\n",
    "        learning_method='online',\n",
    "        random_state=42,\n",
    "        max_iter=10,\n",
    "        n_jobs=4,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "with joblib.parallel_backend(backend='loky', n_jobs=4):\n",
    "    lda_model_ben.fit(train_vec_ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d11d3568-6ef5-4f42-a8c2-bf7276b44c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# panel = pyLDAvis.lda_model.prepare(\n",
    "#     lda_model_ben,\n",
    "#     train_vec_ben,\n",
    "#     vector_ben,\n",
    "#     mds='tsne'\n",
    "# )\n",
    "# panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a8883-3dda-49ff-85e5-97043e46213d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b2eb4-74a8-4948-beb8-b45579e6d0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
